\chapter{Stimatori per l'errore di previsione}
\label{ch:capitolo5}

Inanzitutto occorre introdurre l'errore di previsione (true error) e l'errore apparente.

Si considerino i dati come $x_i =  (\underline{\beta_i},y_i)$ , $i = 1,2,...,n$ dove $x_i$ indica la $i$-esima osservazione presente all'interno del dataset, $\underline{\beta_i}$ è il vettore dei predittori mentre $y_i$ rappresenta la classe di appartenenza.
Si supponga di ottenere una nuova osservazione, che verrà indicata con $x_0 =  (\underline{\beta_0},y_0)$
Si consideri ${L(y,\hat{y})}=I[\hat{y} \neq y]$ come una misura dell'errore tra la risposta $y$ e la previsione $\hat{y}$. Nei casi presentati il riferimento sarà ${L(y,\hat{y})}=I[\hat{y} \neq y]$. \\
L'errore di previsione (reale) è dunque così definito
\begin{equation}
\text{Err} = \mathbb{E}[L(y_0, \hat{y_0})],
\end{equation}
mentre l'errore apparente sarà
\begin{equation}
\overline{\text{err}} = \mathbb{E}[L(y_i, \hat{y_i})] = \frac{1}{n} \sum_{i=1}^{n} L(y_i, \hat{y_i}).
\end{equation}
L'errore apparente andrà a sottostimare l'errore reale, dato che viene calcolato sugli stessi dati sui cui è stato allenato il modello.

\section{Cross-Validation methods}
\label{sec:sezione5.1}

\subsection{Leave-One-Out Cross-Validation}
\label{sec:sezione5.1.1}

Indicando con $\hat{y}^{-i}$ la stima ottenuta rimuovendo la $i$-esima osservazione, la stima tramite leave-one-out cross-validation sarà
\begin{equation}
\widehat{\text{Err}}^{LOOCV} = \mathbb{E}[L(y_i, \hat{y_i}^{-i})] = \frac{1}{n} \sum_{i=1}^{n} L(y_i, \hat{y_i}^{-i}).
\end{equation}

\subsection{k-fold Cross-Validation}
\label{sec:sezione5.1.2}

Per ottenere la stima tramite $k$-fold cross-validation, anzichè escludere la i-esima osservazione, si procede escludendo una parte di osservazioni indicata con $k(i)$. Indicando con $k(i)$ la parte contenente l'osservazione $i$-esima e con $\hat{y}^{-k(i)}$ la stima ottenuta rimuovendo la $k(i)$-esima parte dal training set, la stima tramite $k$-fold cross-validation è
\begin{equation}
\widehat{\text{Err}}^{kCV} = \mathbb{E}[L(y_i, \hat{y_i}^{-k(i)})] = \frac{1}{n} \sum_{i=1}^{n} L(y_i, \hat{y_i}^{-k(i)}).
\end{equation}
La leave-one-out cross-validation si può indicare come una versione della $k$-fold, in cui $k = n$

\subsection{Monte Carlo Cross-Validation}
\label{sec:sezione5.1.3}

A differenza della $k$-fold, dove il dataset viene diviso in $k$ parti ognuna contenente osservazioni uniche e non contenute all'interno delle altre $k-1$ parti, il metodo Monte Carlo consiste nell'estrarre $m = 1,2,...,M$ campioni di ampiezza prefissata senza reinserimento, andando così a creare un numero di training set e test set potenzialmente infinito, dato che le osservazioni all'interno dei vari split possono apparire più volte all'interno del test set. L'errore di previsione viene dunque stimato facendo la media tra gli errori ottenuti da ogni split.
L'idea dietro l'utilizzo del metodo Monte Carlo è quello che utilizzando la k-fold, vengono analizzati solo alcuni dei possibili modi in cui il dataset poteva essere diviso, mentre con il Monte Carlo teoricamente si potrebbero analizzare tutte le possibili partizioni. Il metodo Monte Carlo dunque tende ad avere una minore variabilità rispetto alla k-fold (a patto che venga utilizzato un numero alto di split), ma a costo di un bias maggiore.
La stima tramite MCCV sarà

\begin{equation}
\widehat{\text{Err}}^{MCCV} = \frac{1}{M} \sum_{i=1}^{M} \sum_{i=1}^{n}L(y_{i,m}, \hat{y}_{i,m})/n.
\end{equation}


\section{Bootstrap methods}
\label{sec:sezione5.4}


\subsection{Boostrap Semplice}
\label{sec:sezione5.4.1}

Il bootstrap semplice consiste nell'estrarre con reinserimento dal dataset un numero B di campioni con dimensioni pari al dataset originale. Il modello viene poi allenato su tutti i campioni bootstrap e testato sul dataset di partenza. Una volta ottenuti quindi B errori di previsione, ne viene fatta la media, ottenendo cosi la stima stramite Bootstrap semplice dell'errore di previsione. 
Sia $x^{*}_i =  (\underline{\beta_i}^{*},y^{*}_i)$, $i = 1,2,...,n$ un campione bootstrap, la stima plug-in dell'errore di previsione è
\begin{equation}
\frac{1}{n} \sum_{i=1}^{n} L(y_i, \hat{y}^{*}_i),
\end{equation}
dove $\hat{y}^{*}_i$ indica la previsione ottenuta dal modello allenato sul campione bootstrap.
Questa espressione però è ottenuta da un unico campione bootstrap, ed è dunque troppo variabile (\cite{efron1993}). Per ottenere una stimatore migliore occorre aumentare il numero di campioni bootstrap, così da poter calcolare l'errore medio per ogni campione, e infine fare una media delle stime ottenute da ogni campione boostrap, $b = 1,2,...,B$.
La stima ottenuta tramite il bootstrap semplice è dunque
\begin{equation}
\widehat{\text{Err}}^{boot} = \frac{1}{B} \sum_{b=1}^{B} \sum_{i=1}^{n}L(y_{i,b}, \hat{y}^{*}_{i,b})/n.
\end{equation}



\subsection{Leave-One-Out Bootstrap}
\label{sec:sezione5.4.2}

\subsection{Bootstrap .632}
\label{sec:sezione5.4.3}

\subsection{Bootstrap .632+}
\label{sec:sezione5.4.4}
